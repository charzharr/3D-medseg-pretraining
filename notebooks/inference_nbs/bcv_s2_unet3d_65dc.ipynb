{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gorgeous-treasury",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T04:22:17.556366Z",
     "iopub.status.busy": "2021-09-10T04:22:17.555715Z",
     "iopub.status.idle": "2021-09-10T04:22:20.676277Z",
     "shell.execute_reply": "2021-09-10T04:22:20.674995Z",
     "shell.execute_reply.started": "2021-09-10T04:22:17.556231Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Adding current path: /afs/crc.nd.edu/user/y/yzhang46/_3DPRE/src\n"
     ]
    }
   ],
   "source": [
    "## General Imports from all libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "import pathlib\n",
    "import glob\n",
    "import time\n",
    "import math, random\n",
    "import pprint\n",
    "import collections\n",
    "import numbers, string\n",
    "\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "from PIL import Image\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "curr_path = pathlib.Path(os.getcwd()).absolute()\n",
    "\n",
    "cards = !echo $SGE_HGR_gpu_card\n",
    "!export CUDA_VISIBLE_DEVICES=\"${SGE_HGR_gpu_card// /,}\"\n",
    "device = torch.device(f\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "# Import custom files for this project\n",
    "dest_path = str(curr_path.parent.parent)\n",
    "if dest_path not in sys.path:\n",
    "    print('Adding current path:', dest_path)\n",
    "    sys.path.append(str(dest_path))\n",
    "\n",
    "from run_experiment import batch_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-black",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T04:00:18.369643Z",
     "iopub.status.busy": "2021-09-10T04:00:18.369060Z",
     "iopub.status.idle": "2021-09-10T04:00:20.853714Z",
     "shell.execute_reply": "2021-09-10T04:00:20.852213Z",
     "shell.execute_reply.started": "2021-09-10T04:00:18.369586Z"
    },
    "tags": []
   },
   "source": [
    "# (0909) Inference with Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "olympic-signal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T04:29:23.090318Z",
     "iopub.status.busy": "2021-09-10T04:29:23.089796Z",
     "iopub.status.idle": "2021-09-10T04:29:23.172080Z",
     "shell.execute_reply": "2021-09-10T04:29:23.170919Z",
     "shell.execute_reply.started": "2021-09-10T04:29:23.090265Z"
    }
   },
   "outputs": [],
   "source": [
    "## Inference Constants\n",
    "infer_batch_size = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "statutory-input",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T04:22:29.652719Z",
     "iopub.status.busy": "2021-09-10T04:22:29.652083Z",
     "iopub.status.idle": "2021-09-10T04:22:47.555869Z",
     "shell.execute_reply": "2021-09-10T04:22:47.554745Z",
     "shell.execute_reply.started": "2021-09-10T04:22:29.652663Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Loading config (./configs/ftbcv_train.yaml).. done.\n",
      "üí† UNet3D-PGL model initiated with n_classes=14, \n",
      "   n_input=1, activation=relu, \n",
      "   params=19,074,510, trainable_params=19,074,510.\n",
      "<All keys matched successfully>\n",
      "Collecting data samples:\n",
      "    Took 1.38s for sample creation.\n",
      "    Took 1.46s for sample creation.    Took 1.47s for sample creation.\n",
      "\n",
      "    Took 1.53s for sample creation.\n",
      "    Took 1.68s for sample creation.\n",
      "    Took 1.76s for sample creation.    Took 1.76s for sample creation.\n",
      "\n",
      "    Took 1.81s for sample creation.\n",
      "    Took 1.93s for sample creation.\n",
      "    Took 1.97s for sample creation.\n",
      "    Took 2.11s for sample creation.\n",
      "    Took 2.27s for sample creation.\n",
      "    Took 2.31s for sample creation.\n",
      "    Took 2.33s for sample creation.\n",
      "    Took 2.38s for sample creation.\n",
      "    Took 2.43s for sample creation.\n",
      "    Took 2.44s for sample creation.\n",
      "    Took 2.64s for sample creation.\n",
      "    Took 2.68s for sample creation.\n",
      "    Took 2.75s for sample creation.\n",
      "    Took 2.80s for sample creation.\n",
      "    Took 3.02s for sample creation.\n",
      "    Took 3.24s for sample creation.\n",
      "    Took 1.73s for sample creation.\n",
      "    Took 3.49s for sample creation.\n",
      "    Took 1.34s for sample creation.\n",
      "    Took 1.15s for sample creation.\n",
      "    Took 2.05s for sample creation.\n",
      "    Took 1.39s for sample creation.\n",
      "    Took 1.95s for sample creation.\n",
      "[Took 13.61s to get samples!]\n",
      "\n",
      "Train Data Components:\n",
      "üí† ScaledForegroundCropper3d initiated (fg_p=0.666). \n",
      "   final_shape=[64, 160, 160], scale_range=[(1.1, 1.4), (1.1, 1.4), (1.1, 1.4)]\n",
      "   default_interpolation=trilinear, ret_record=True\n",
      "üí† BCVSampleSet created with 18 samples. \n",
      "   Train=True, Crops/Vol=80, Virtual-Size=1440, #Transforms=5.\n",
      "   Indices: [0, 1, 2, 5, 6, 8, 11, 13, 15, 17, 19, 20, 22, 24, 25, 26, 28, 29]\n",
      "üí† Torch Dataloader initialized with 2 workers!\n",
      "   Batch-size=2, Shuffle=True. \n",
      "\n",
      "\n",
      "Validation Data Components:\n",
      "üí† BCVSampleSet created with 6 samples. \n",
      "   Train=False, Crops/Vol=1, Virtual-Size=6, #Transforms=0.\n",
      "   Indices: [3, 7, 10, 16, 18, 27]\n",
      "\n",
      "Test Data Components:\n",
      "üí† BCVSampleSet created with 6 samples. \n",
      "   Train=False, Crops/Vol=1, Virtual-Size=6, #Transforms=0.\n",
      "   Indices: [4, 9, 12, 14, 21, 23]\n",
      "[Took 13.61 sec to load all data.]\n"
     ]
    }
   ],
   "source": [
    "## ------------- Get Config ------------\n",
    "from configs import get_config\n",
    "cfg = get_config('./configs/ftbcv_train.yaml', merge_default=False)\n",
    "cfg.experiment.distributed = False\n",
    "cfg.experiment.rank = 0\n",
    "cfg.experiment.device = device\n",
    "cfg.experiment.gpu_idxs = cards[0].split(',')\n",
    "\n",
    "## ------------- Get Checkpoint -------------\n",
    "cp_file = '(0905bcv-2g)TUNE_genunet_adam_cew+bdice_s2_finetune_bcv_ep82_last.pth'\n",
    "cp_path = pathlib.Path(dest_path) / 'experiments' / 'finetune_bcv' / cp_file\n",
    "checkpoint = torch.load(cp_path, map_location='cpu')\n",
    "\n",
    "## -------------- Get Model --------------\n",
    "state_dict = checkpoint['state_dict']\n",
    "new_state_dict = collections.OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    new_state_dict['.'.join(k.split('.')[1:])] = v\n",
    "del state_dict\n",
    "\n",
    "from experiments.ftbcv.ftbcv_unet3d import UNet3D as genesis_unet3d\n",
    "model = genesis_unet3d(n_input=1, n_class=14, act='relu')\n",
    "print(model.load_state_dict(new_state_dict))\n",
    "model = model.to(device)\n",
    "\n",
    "## ----------------- Get Data ----------------\n",
    "from experiments.ftbcv.data_setup import get_data_components\n",
    "data_d = get_data_components(cfg)\n",
    "val_set = data_d['val_set']\n",
    "test_set = data_d['test_set']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cooked-surgeon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T04:57:06.535577Z",
     "iopub.status.busy": "2021-09-10T04:57:06.535202Z",
     "iopub.status.idle": "2021-09-10T05:03:03.404864Z",
     "shell.execute_reply": "2021-09-10T05:03:03.403174Z",
     "shell.execute_reply.started": "2021-09-10T04:57:06.535544Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 2 -> 2\n",
      " üñºÔ∏è  Inference for example 1.\n",
      "     Getting predictions for 24 batches.\n",
      "Completed inference for vol 1 (34.54 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 2.\n",
      "     Getting predictions for 24 batches.\n",
      "Completed inference for vol 2 (34.62 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 3.\n",
      "     Getting predictions for 24 batches.\n",
      "Completed inference for vol 3 (34.55 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 4.\n",
      "     Getting predictions for 16 batches.\n",
      "Completed inference for vol 4 (22.91 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 5.\n",
      "     Getting predictions for 16 batches.\n",
      "Completed inference for vol 5 (23.05 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 6.\n",
      "     Getting predictions for 16 batches.\n",
      "Completed inference for vol 6 (23.06 sec).\n",
      "\n",
      "(Val) Example 1 \n",
      "       Dice: 0.63 \n",
      "        [0.992 0.728 0.761 0.722 0.155 0.678 0.844 0.456 0.915 0.827 0.545 0.244\n",
      " 0.62  0.288] \n",
      "       Jaccard: 0.50 \n",
      "        [0.984 0.572 0.615 0.565 0.084 0.513 0.731 0.295 0.843 0.705 0.375 0.139\n",
      " 0.449 0.169]\n",
      "(Val) Example 2 \n",
      "       Dice: 0.71 \n",
      "        [0.997 0.73  0.248 0.134 0.819 0.772 0.903 0.752 0.876 0.862 0.748 0.612\n",
      " 0.73  0.708] \n",
      "       Jaccard: 0.59 \n",
      "        [0.993 0.575 0.142 0.072 0.693 0.628 0.822 0.603 0.779 0.757 0.597 0.441\n",
      " 0.575 0.548]\n",
      "(Val) Example 3 \n",
      "       Dice: 0.64 \n",
      "        [0.993 0.614 0.868 0.856 0.465 0.596 0.858 0.616 0.898 0.624 0.587 0.421\n",
      " 0.497 0.087] \n",
      "       Jaccard: 0.51 \n",
      "        [0.986 0.443 0.766 0.748 0.303 0.425 0.751 0.445 0.815 0.453 0.415 0.267\n",
      " 0.33  0.045]\n",
      "(Val) Example 4 \n",
      "       Dice: 0.78 \n",
      "        [0.995 0.904 0.881 0.89  0.722 0.721 0.944 0.773 0.912 0.863 0.627 0.645\n",
      " 0.58  0.473] \n",
      "       Jaccard: 0.66 \n",
      "        [0.99  0.824 0.788 0.802 0.565 0.564 0.895 0.631 0.838 0.76  0.456 0.476\n",
      " 0.408 0.31 ]\n",
      "(Val) Example 5 \n",
      "       Dice: 0.78 \n",
      "        [0.992 0.815 0.887 0.865 0.545 0.648 0.819 0.84  0.9   0.889 0.749 0.563\n",
      " 0.707 0.713] \n",
      "       Jaccard: 0.66 \n",
      "        [0.985 0.688 0.797 0.762 0.375 0.48  0.693 0.724 0.818 0.801 0.598 0.392\n",
      " 0.547 0.554]\n",
      "(Val) Example 6 \n",
      "       Dice: 0.72 \n",
      "        [0.995 0.835 0.846 0.866 0.    0.765 0.897 0.648 0.906 0.804 0.673 0.731\n",
      " 0.581 0.523] \n",
      "       Jaccard: 0.60 \n",
      "        [0.989 0.717 0.733 0.764 0.    0.619 0.813 0.479 0.829 0.672 0.507 0.576\n",
      " 0.41  0.354]\n",
      "StopWatch(Val) took 2.98 min\n",
      "{'dice_mean': 0.7092652022838593, 'jaccard_mean': 0.588559885819753}\n",
      " üñºÔ∏è  Inference for example 1.\n",
      "     Getting predictions for 24 batches.\n",
      "Completed inference for vol 1 (34.26 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 2.\n",
      "     Getting predictions for 24 batches.\n",
      "Completed inference for vol 2 (34.60 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 3.\n",
      "     Getting predictions for 16 batches.\n",
      "Completed inference for vol 3 (23.01 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 4.\n",
      "     Getting predictions for 16 batches.\n",
      "Completed inference for vol 4 (22.89 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 5.\n",
      "     Getting predictions for 24 batches.\n",
      "Completed inference for vol 5 (34.57 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 6.\n",
      "     Getting predictions for 16 batches.\n",
      "Completed inference for vol 6 (22.99 sec).\n",
      "\n",
      "(Test) Example 1 \n",
      "       Dice: 0.55 \n",
      "        [0.993 0.614 0.087 0.473 0.502 0.575 0.892 0.615 0.858 0.692 0.57  0.214\n",
      " 0.396 0.282] \n",
      "       Jaccard: 0.43 \n",
      "        [0.985 0.443 0.045 0.31  0.335 0.403 0.806 0.444 0.751 0.529 0.399 0.12\n",
      " 0.247 0.164]\n",
      "(Test) Example 2 \n",
      "       Dice: 0.71 \n",
      "        [0.993 0.656 0.824 0.869 0.615 0.737 0.911 0.439 0.823 0.669 0.655 0.521\n",
      " 0.595 0.619] \n",
      "       Jaccard: 0.57 \n",
      "        [0.985 0.489 0.701 0.768 0.444 0.583 0.837 0.281 0.7   0.503 0.487 0.352\n",
      " 0.423 0.449]\n",
      "(Test) Example 3 \n",
      "       Dice: 0.56 \n",
      "        [0.993 0.656 0.662 0.557   nan 0.304 0.846 0.547 0.515 0.563 0.227 0.416\n",
      " 0.568 0.476] \n",
      "       Jaccard: 0.42 \n",
      "        [0.986 0.488 0.495 0.386   nan 0.179 0.733 0.377 0.347 0.391 0.128 0.263\n",
      " 0.397 0.313]\n",
      "(Test) Example 4 \n",
      "       Dice: 0.59 \n",
      "        [0.994 0.719 0.294 0.589 0.768 0.514 0.895 0.812 0.797 0.749 0.05  0.153\n",
      " 0.438 0.443] \n",
      "       Jaccard: 0.47 \n",
      "        [0.989 0.561 0.172 0.417 0.624 0.346 0.81  0.683 0.662 0.598 0.026 0.083\n",
      " 0.28  0.284]\n",
      "(Test) Example 5 \n",
      "       Dice: 0.77 \n",
      "        [0.995 0.897 0.874 0.881 0.778 0.732 0.905 0.796 0.931 0.878 0.575 0.407\n",
      " 0.73  0.421] \n",
      "       Jaccard: 0.66 \n",
      "        [0.99  0.813 0.776 0.788 0.636 0.577 0.826 0.661 0.87  0.783 0.403 0.256\n",
      " 0.575 0.266]\n",
      "(Test) Example 6 \n",
      "       Dice: 0.71 \n",
      "        [0.992 0.836 0.777 0.834 0.562 0.695 0.894 0.618 0.792 0.793 0.629 0.478\n",
      " 0.53  0.569] \n",
      "       Jaccard: 0.58 \n",
      "        [0.984 0.719 0.635 0.716 0.391 0.533 0.809 0.447 0.656 0.658 0.459 0.314\n",
      " 0.361 0.397]\n",
      "StopWatch(Test) took 2.97 min\n",
      "{'dice_mean': 0.6499554316202799, 'jaccard_mean': 0.5204800963401794}\n"
     ]
    }
   ],
   "source": [
    "## Run Val Inference\n",
    "print('batch_size:', cfg.test.batch_size, '->', infer_batch_size)\n",
    "cfg.test.batch_size = infer_batch_size\n",
    "metrics_queue = torch.multiprocessing.Queue()\n",
    "\n",
    "from run_experiment import test_metrics\n",
    "print(test_metrics(cfg, model, val_set, 0, metrics_queue, len(val_set),\n",
    "                   name='val', overlap_perc=0.2))\n",
    "print(test_metrics(cfg, model, test_set, 0, metrics_queue, len(test_set),\n",
    "                   name='test', overlap_perc=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-diagnosis",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T04:06:03.621831Z",
     "iopub.status.busy": "2021-09-10T04:06:03.621257Z",
     "iopub.status.idle": "2021-09-10T04:06:04.264520Z",
     "shell.execute_reply": "2021-09-10T04:06:04.263154Z",
     "shell.execute_reply.started": "2021-09-10T04:06:03.621776Z"
    },
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# (0901) Pengfei Inference Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-fortune",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T05:34:03.174227Z",
     "iopub.status.busy": "2021-09-01T05:34:03.173579Z",
     "iopub.status.idle": "2021-09-01T05:34:03.240663Z",
     "shell.execute_reply": "2021-09-01T05:34:03.239433Z",
     "shell.execute_reply.started": "2021-09-01T05:34:03.174147Z"
    },
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Data Collection and Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mathematical-malaysia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:38:35.095024Z",
     "iopub.status.busy": "2021-09-02T17:38:35.094743Z",
     "iopub.status.idle": "2021-09-02T17:38:35.146658Z",
     "shell.execute_reply": "2021-09-02T17:38:35.145565Z",
     "shell.execute_reply.started": "2021-09-02T17:38:35.094993Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_imgs_masks_info(args):\n",
    "    images_f, mask_f = args\n",
    "    # 1. Read image and preprocess (clamp + normalize)\n",
    "    sitk_image = sitk.ReadImage(image_f, sitk.sitkInt16)\n",
    "    sitk_image = sitk.Clamp(sitk_image, sitk.sitkInt16, -1024, 325)\n",
    "    sitk_image = sitk.NormalizeImageFilter().Execute(sitk_image)\n",
    "    image_tensor = torch.from_numpy(sitk.GetArrayFromImage(sitk_image))\n",
    "    image_tensor = image_tensor.float()\n",
    "\n",
    "    # 2. Read mask and convert it to one-hot\n",
    "    sitk_mask = sitk.ReadImage(mask_f, sitk.sitkInt64)\n",
    "    mask_tensor = torch.from_numpy(sitk.GetArrayFromImage(sitk_mask))\n",
    "\n",
    "    shape = image_tensor.shape\n",
    "    oh_shape = [num_classes] + list(shape)\n",
    "    mask_oh_tensor = torch.zeros(oh_shape, dtype=torch.int32)\n",
    "    mask_oh_tensor.scatter_(0, mask_tensor.unsqueeze(0), 1)\n",
    "    \n",
    "    info = {\n",
    "        'origin': sitk_image.GetOrigin(),\n",
    "        'spacing': sitk_image.GetSpacing(),\n",
    "        'direction': sitk_image.GetDirection()\n",
    "    }\n",
    "    return image_tensor, mask_oh_tensor, info\n",
    "    \n",
    "    \n",
    "class MockDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, mask_files, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.image_files = image_files  # list of image files\n",
    "        self.mask_files = mask_files  # list of mask files\n",
    "        \n",
    "        # Get image tensors and store permanently\n",
    "        self.images, self.masks, self.image_info = [], [], []\n",
    "        args = []\n",
    "        for image_f, mask_f in zip(image_files, mask_files):\n",
    "            args.append((image_f, mask_f))\n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "        info_d = self.image_info[idx]\n",
    "        return image, mask, info_d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "posted-beginning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:38:35.148093Z",
     "iopub.status.busy": "2021-09-02T17:38:35.147671Z",
     "iopub.status.idle": "2021-09-02T17:38:54.653582Z",
     "shell.execute_reply": "2021-09-02T17:38:54.652372Z",
     "shell.execute_reply.started": "2021-09-02T17:38:35.148042Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 19.28532838821411 sec to load 6 test images.\n"
     ]
    }
   ],
   "source": [
    "bcv_dir = pathlib.Path('/afs/crc.nd.edu/user/y/yzhang46/datasets/BCV-2015')\n",
    "train_image_dir = bcv_dir / 'train' / 'img_nii'\n",
    "train_mask_dir = bcv_dir / 'train' / 'label_nii'\n",
    "\n",
    "images = sorted(glob.glob(str(train_image_dir) + '/*.nii.gz'))\n",
    "masks = sorted(glob.glob(str(train_mask_dir) + '/*.nii.gz'))\n",
    "\n",
    "start = time.time()\n",
    "test_size = 6\n",
    "num_classes = 14\n",
    "test_set = MockDataset(images[:test_size], masks[:test_size], num_classes)\n",
    "print(f'Took {time.time() - start} sec to load {test_size} test images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-serve",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T05:34:44.322598Z",
     "iopub.status.busy": "2021-09-01T05:34:44.321994Z",
     "iopub.status.idle": "2021-09-01T05:34:44.386440Z",
     "shell.execute_reply": "2021-09-01T05:34:44.385229Z",
     "shell.execute_reply.started": "2021-09-01T05:34:44.322544Z"
    },
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "clear-aspect",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:38:54.655645Z",
     "iopub.status.busy": "2021-09-02T17:38:54.655361Z",
     "iopub.status.idle": "2021-09-02T17:38:54.998082Z",
     "shell.execute_reply": "2021-09-02T17:38:54.997212Z",
     "shell.execute_reply.started": "2021-09-02T17:38:54.655614Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí† UNet3D-PGL model initiated with n_classes=14, \n",
      "   n_input=1, activation=relu, \n",
      "   params=19,074,510, trainable_params=19,074,510.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = '(0831)bcv-scratch_adam_dice_s3_finetune_bcv_ep499_last.pth'\n",
    "checkpoint = torch.load(file, map_location='cpu')\n",
    "\n",
    "from lib.nets.volumetric.resunet3d import UNet3D\n",
    "# model = UNet3D(1, 14, final_sigmoid=False, is_segmentation=False)\n",
    "\n",
    "from experiments.finetune_bcv.ftbcv_unet3d import UNet3D as genesis_unet3d\n",
    "model = genesis_unet3d(n_input=1, n_class=14, act='relu')\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-medicare",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "republican-carbon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:39:31.145551Z",
     "iopub.status.busy": "2021-09-02T17:39:31.144913Z",
     "iopub.status.idle": "2021-09-02T17:40:53.492826Z",
     "shell.execute_reply": "2021-09-02T17:40:53.491616Z",
     "shell.execute_reply.started": "2021-09-02T17:39:31.145495Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚≠ê Inference for example 1..\n",
      "Batch 1 / 16\n",
      "Batch 2 / 16\n",
      "Batch 3 / 16\n",
      "Batch 4 / 16\n",
      "Batch 5 / 16\n",
      "Batch 6 / 16\n",
      "Batch 7 / 16\n",
      "Batch 8 / 16\n",
      "Batch 9 / 16\n",
      "Batch 10 / 16\n",
      "Batch 11 / 16\n",
      "Batch 12 / 16\n",
      "Batch 13 / 16\n",
      "Batch 14 / 16\n",
      "Batch 15 / 16\n",
      "Batch 16 / 16\n",
      "Aggregate (divide):  3.136298656463623\n",
      "Aggregate:  14.577434301376343\n",
      "Getting image metrics..\n",
      "0.06910467892885208 [0.967 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.   ]\n",
      "0.0669272169470787 [0.937 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.   ]\n",
      "Mets time: 18.30\n",
      "Saving image..\n",
      "Completed inference for test volume 1 (82.26).\n"
     ]
    }
   ],
   "source": [
    "from data.transforms.crops.inference import ChopBatchAggregate3d as CBA\n",
    "\n",
    "num_classes = 14\n",
    "device = 'cuda'\n",
    "dataset = test_set\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(len(dataset)):\n",
    "        start_vol = time.time()\n",
    "        print(f'‚≠ê Inference for example {i+1}..')\n",
    "        image, mask, info = dataset[i]  # image: DxHxW, mask: CxDxHxW\n",
    "                                        #  image: float32, mask: int32\n",
    "        \n",
    "        # Create Chop, batch, aggregator object\n",
    "        image = image   # faster calc with GPUs\n",
    "        mask = mask\n",
    "        cba = CBA(image, (48, 160, 160), (0, 0, 0), 4, num_classes)\n",
    "        \n",
    "        # Run inference on batches of crops of image\n",
    "        for bidx, batch in enumerate(cba):\n",
    "            print(f'Batch {bidx + 1} / {len(cba)}')\n",
    "            crops, locations = batch\n",
    "            crops = crops.to(device)\n",
    "            \n",
    "            logits = model(crops)['out']\n",
    "    \n",
    "            cba.add_batch_predictions(logits.cpu(), locations, act='none')\n",
    "                # NOTE: in this case, we are averaging logits, if you want\n",
    "                #  to average probabilities instead, use act='softmax'\n",
    "        \n",
    "        # Get final predictions, calculate metrics\n",
    "        agg_predictions = cba.aggregate(ret='one_hot', cpu=True, numpy=False)\n",
    "        \n",
    "        print(f'Getting image metrics..')\n",
    "        start = time.time()\n",
    "        mets = batch_metrics(agg_predictions.unsqueeze(0), mask.unsqueeze(0))\n",
    "            # preds are CxDxHxW, but batch input takes 1xCxDxHxW\n",
    "        print(mets['dice_mean'], mets['dice_class'])\n",
    "        print(mets['jaccard_mean'], mets['jaccard_class'])\n",
    "        print(f'Mets time: {time.time() - start:.2f}')\n",
    "        \n",
    "        # Convert from 1hot to id and save prediction volume\n",
    "        print(f'Saving image..')\n",
    "        id_preds = agg_predictions.argmax(0).numpy().astype(np.uint16)\n",
    "        sitk_pred = sitk.GetImageFromArray(id_preds, isVector=False)\n",
    "        sitk_pred.SetOrigin(info['origin'])\n",
    "        sitk_pred.SetSpacing(info['spacing'])\n",
    "        sitk_pred.SetDirection(info['direction'])\n",
    "        sitk.WriteImage(sitk_pred, 'prediction.nii.gz')\n",
    "        \n",
    "        elapsed = time.time() - start_vol\n",
    "        print(f'Completed inference for test volume {i+1} ({elapsed:.2f}).')\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "incorporate-arrival",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:46:07.299252Z",
     "iopub.status.busy": "2021-09-02T17:46:07.298580Z",
     "iopub.status.idle": "2021-09-02T17:46:07.426552Z",
     "shell.execute_reply": "2021-09-02T17:46:07.425289Z",
     "shell.execute_reply.started": "2021-09-02T17:46:07.299195Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.argmax(1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-keeping",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "behavioral-graduation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T03:36:49.626134Z",
     "iopub.status.busy": "2021-05-06T03:36:49.625522Z",
     "iopub.status.idle": "2021-05-06T03:36:53.788730Z",
     "shell.execute_reply": "2021-05-06T03:36:53.787232Z",
     "shell.execute_reply.started": "2021-05-06T03:36:49.626003Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "## Fast Import\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "import string\n",
    "import pathlib\n",
    "import time\n",
    "import math, random\n",
    "import pprint\n",
    "import yaml\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import albumentations as A\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "curr_path = pathlib.Path(os.getcwd())\n",
    "\n",
    "cards = !echo $SGE_HGR_gpu_card\n",
    "device = torch.device(f\"cuda:{cards[0]}\" if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "sys.path.append(str(curr_path.parent / 'src'))\n",
    "import lib\n",
    "from lib.data.decathlon import dataset as decathlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fourth-clothing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T04:56:21.243426Z",
     "iopub.status.busy": "2021-05-06T04:56:21.242856Z",
     "iopub.status.idle": "2021-05-06T04:56:21.326633Z",
     "shell.execute_reply": "2021-05-06T04:56:21.325710Z",
     "shell.execute_reply.started": "2021-05-06T04:56:21.243373Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[1, 1, 0],\n",
      "           [0, 0, 0]]],\n",
      "\n",
      "\n",
      "         [[[1, 0, 0],\n",
      "           [1, 0, 1]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1, 0, 1],\n",
      "           [0, 1, 1]]],\n",
      "\n",
      "\n",
      "         [[[1, 0, 1],\n",
      "           [0, 0, 0]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0, 0, 1],\n",
      "           [0, 1, 1]]],\n",
      "\n",
      "\n",
      "         [[[1, 0, 0],\n",
      "           [1, 1, 0]]]]])\n",
      "tensor([[[[[0, 0, 1],\n",
      "           [0, 0, 0]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0, 0, 0],\n",
      "           [0, 0, 1]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1, 1, 0],\n",
      "           [0, 0, 1]]]]])\n",
      "{'dice_c': tensor([0.6364, 0.1538]),\n",
      " 'fn': tensor([[3., 1.],\n",
      "        [2., 1.],\n",
      "        [1., 2.]]),\n",
      " 'fn_c': tensor([6., 4.]),\n",
      " 'fp': tensor([[0., 3.],\n",
      "        [1., 2.],\n",
      "        [1., 2.]]),\n",
      " 'fp_c': tensor([2., 7.]),\n",
      " 'hausdorff_c': None,\n",
      " 'jaccard_c': tensor([0.4667, 0.0833]),\n",
      " 'sensitivity_c': tensor([0.5385, 0.2000]),\n",
      " 'tp': tensor([[2., 0.],\n",
      "        [3., 0.],\n",
      "        [2., 1.]]),\n",
      " 'tp_c': tensor([7., 1.])}\n"
     ]
    }
   ],
   "source": [
    "from lib.assess import metrics3d as M\n",
    "from lib.assess import losses3d as L\n",
    "\n",
    "pred = torch.randint(0, 2, (3, 2, 1, 2, 3))\n",
    "targ = torch.randint(0, 2, (3, 1, 1, 2, 3))\n",
    "d = L.cross_entropy_loss(pred, targ)\n",
    "print(pred)\n",
    "print(targ)\n",
    "pprint.pprint(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-birth",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "helpful-values",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-03T07:04:47.394513Z",
     "iopub.status.busy": "2021-05-03T07:04:47.393942Z",
     "iopub.status.idle": "2021-05-03T07:04:47.463762Z",
     "shell.execute_reply": "2021-05-03T07:04:47.462397Z",
     "shell.execute_reply.started": "2021-05-03T07:04:47.394460Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_default_df(df, train=0.6, val=0.2, test=0.2):\n",
    "    df = df.copy(deep=True)\n",
    "    N = len(df)\n",
    "    N_train = math.ceil(N * train)\n",
    "    if N_train % 2 == 1:\n",
    "        N_train += 1\n",
    "    N_test = math.ceil(N * test)\n",
    "    N_val = N - N_train - N_test\n",
    "    \n",
    "    indices = set(range(N))\n",
    "    train_indices = set(random.sample(indices, k=N_train))\n",
    "    indices = indices.difference(train_indices)\n",
    "    test_indices = set(random.sample(indices, k=N_test))\n",
    "    val_indices = indices.difference(test_indices)\n",
    "    \n",
    "    for i, S in df.iterrows():\n",
    "        subset = 'train'\n",
    "        if i in test_indices:\n",
    "            subset = 'test'\n",
    "        elif i in val_indices:\n",
    "            subset = 'val'\n",
    "        S['subset'] = subset\n",
    "    print(f\"Out of {N} exs, sampled {len(train_indices)}-{len(val_indices)}-{len(test_indices)}\")\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-prisoner",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Decathlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "legal-orientation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-03T06:16:50.870898Z",
     "iopub.status.busy": "2021-05-03T06:16:50.870308Z",
     "iopub.status.idle": "2021-05-03T06:16:52.187322Z",
     "shell.execute_reply": "2021-05-03T06:16:52.185281Z",
     "shell.execute_reply.started": "2021-05-03T06:16:50.870845Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_d = decathlon.get_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "failing-evaluation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-03T07:08:00.896819Z",
     "iopub.status.busy": "2021-05-03T07:08:00.896250Z",
     "iopub.status.idle": "2021-05-03T07:08:01.623214Z",
     "shell.execute_reply": "2021-05-03T07:08:01.622097Z",
     "shell.execute_reply.started": "2021-05-03T07:08:00.896766Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3: Liver\n",
      "Out of 131 exs, sampled 80-24-27\n",
      "Out of 131 exs, sampled 80-24-27\n",
      "Out of 131 exs, sampled 80-24-27\n",
      "Task 6: Lung\n",
      "Out of 63 exs, sampled 38-12-13\n",
      "Out of 63 exs, sampled 38-12-13\n",
      "Out of 63 exs, sampled 38-12-13\n",
      "Task 7: Pancreas\n",
      "Out of 281 exs, sampled 170-54-57\n",
      "Out of 281 exs, sampled 170-54-57\n",
      "Out of 281 exs, sampled 170-54-57\n",
      "Task 8: HepaticVessel\n",
      "Out of 303 exs, sampled 182-60-61\n",
      "Out of 303 exs, sampled 182-60-61\n",
      "Out of 303 exs, sampled 182-60-61\n",
      "Task 9: Spleen\n",
      "Out of 41 exs, sampled 26-6-9\n",
      "Out of 41 exs, sampled 26-6-9\n",
      "Out of 41 exs, sampled 26-6-9\n",
      "Task 10: Colon\n",
      "Out of 126 exs, sampled 76-24-26\n",
      "Out of 126 exs, sampled 76-24-26\n",
      "Out of 126 exs, sampled 76-24-26\n"
     ]
    }
   ],
   "source": [
    "### Loop through dataframes and ..\n",
    "#    1. save default csv\n",
    "\n",
    "for i, task in enumerate(decathlon.TASKS):\n",
    "    if not task: continue\n",
    "    print(f'Task {i+1}: {task}')\n",
    "    tdf = df_d[task]\n",
    "    img_path = pathlib.Path(tdf.iloc[0]['image'])\n",
    "    task_path = img_path.parent.parent\n",
    "    # tdf.to_csv(task_path / 'default_df.csv')\n",
    "    \n",
    "    splits_path = task_path / 'splits'\n",
    "    if not splits_path.exists():\n",
    "        splits_path.mkdir()\n",
    "    lab_df = tdf[tdf['subset'] == 'train']\n",
    "    \n",
    "    for version in ('a', 'b', 'c'):\n",
    "        split_df = split_default_df(lab_df)\n",
    "        split_df.to_csv(splits_path / f'{task.lower()}_60-20-20split_{version}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


# ---- ##  Experiment Setup, Logging Specifications, Environment  ## ---- #
experiment:
  description: |
    > CT data pretraining for spatial prediction tasks (not just proposed vec).
  id: "(0219_r2u101_pretr_mg)ep300_adamw,002-wd0-cos_mse_r1"     # for wandb run identification

  name: 'prevec'   # for experiment module identification
  project: 'miccai22_pretrain3d'

  debug:                                            # (Correct Alignment)
    mode: False                                     # < Check
    overfitbatch: False                             # < Check
    wandb: True                                     # < Check
    save: True                                      # < Check
    break_train_iter: False                         # < Check
    break_test_iter: False                          # < Check
    test_every_n_epochs: 1
  distributed: False
  seed: 420
  hpsamp: ""
  adjust_by_comp: False  # adjust training params based on specific components

  checkpoint:
    file: ''


# ---- ##  Pretaraining Task-specific Settings  ## ---- #

tasks:
  name: 'mg'

  mg:
    test: False
    num_classes: 1
    
    prediction_head: False
    prediction_head_dims: 128
    
    t_mg_flip: 0.4
    t_mg_shuffle: 0.5
    t_mg_shuffle_times: 2000
    t_mg_nonlinear: 0.9
    t_mg_paint: 0.9
    t_mg_inpaint: 0.3  # out-paint is 1-inpaint_p
    t_mg_inpaint_uniform: True
    t_mg_inpaint_times: 10
    t_mg_outpaint_uniform: True
    t_mg_outpaint_times: 10
    
  universal:
    test: False
    
    t_mg_flip: 0.4
    t_mg_shuffle: 0.5
    t_mg_nonlinear: 0.9
    t_mg_paint: 0.9
    t_mg_inpaint: 0.8  # out-paint is 1-inpaint_p
    
  rubikpp:
    test: False
    n: 7  # number of sub-cubes per dim
    m: 4  # number of cube levels to rotate per axes

  prevec:
    test: True
    loss: 'spherical'
    pred_indices: [0,1,2]  # [0,1,2,3,4,5,6,7,8]
    pred_mag: False
    r_loss: 'mse'
    ang_loss: 'mse'

  # rot:
  #   rot_x_vals: []  # rot per axis are overwritten & flips are 0
  #   rot_y_vals: []
  #   rot_z_vals: []
  
  # rel: []

  # scale:
  #   scales: []


# ---- ##  Data Preprocessing, Loading, Transformation  ## ---- #

data:  # describing project-wide data specifications
  name: 'pretrain'

  pretrain:  # mmwhs, bcv, msd-liver, msd-lung
    num_classes: 1
  mmwhs:
    num_classes: 8  # including background
    split: 'lab_df.csv'  # 'lab_df.csv' 'fs50_8-2_a.csv'
      # 16 train, 4 test
  bcv:
    num_classes: 14
    split: 'cotr70-30_fs25_a.csv'  # 60-20-20.csv, cotr70-30_fs100.csv
  msd_spleen:
    num_classes: 2  # including background
    split: 'spleen_fs10_8-2_a.csv' # 41 total, 32 train + 9 test
      # spleen_80-20.csv


# Model / Criterion / Other nn.Module Specifications
model:
  name: 'res2unet3d'  # nnunet3d, hrnet3d, denseunet3d, unet3p3d, res2unet3d
  init: 'kaiming'
  sync_bn: True
  norm: 'batchnorm'
  act: 'relu'

  # Backbone Settings
  denseunet3d:
    layers: 201
  hrnet3d:
    cfg: 'seg_hrnetv2_w48.yaml'
  res2unet3d:
    layers: 101
    base_width: 26  # default: 26
  # Prediction Head Settings (only applied if task uses component)



# ---- ##  Training: iterations, criterion, optimization, etc.  ## ---- #

train:
  deep_sup: False

  epochs: 300
  start_epoch: 0

  dataset_sample_multiplier: 1
  batch_size: 2   # ⚠️⚠️⚠️ actual batch-size is double this!!!!
  batch_crops_per_volume: 6  # real batch-size is batch_size * BCperVol
  num_workers: 5

  patch_size: [96, 96, 96] # [64, 128, 128], [32, 160, 160]
  scale_range: [0.75, 1.25]   # 48 -> 192
  cubic_crop: True
  min_mean_crop_thresh: 0.25  # threshold of mean patch value to avoid air
  
  t_flip_x: 0.5  # flip on all 3 axis
  t_flip_y: 0.5
  t_flip_z: 0.5
  t_rot_x_vals: []
  t_rot_y_vals: []
  t_rot_z_vals: []
  
  t_gn: 0.  # gaussian noise
  t_gb: 0.2  # gaussian blur
  t_intensity_scale: 0.2
  t_gamma: 0.2

  optimizer:
    name: 'adamw'
    lr: 0.002  # usually 0.01 for FS50 & above
    wt_decay: 0.0
    
    nesterov:
      momentum: 0.99
    sgd:
      momentum: 0.9
    adamw:
      betas: [0.9, 0.999]

  scheduler:
    name: 'cosine'
    rampup_rates: []
    min_lr: 0.000001
    
    poly:
      power: 0.9

    step:
      factor: 0.2
      steps: [0.3, 0.6, 0.9]
    
    exponential:
      exp_factor: 0.95

test:
  batch_size: 20

  patch_size: [96, 96, 96]  # [64, 128, 128], [32, 160, 160]
  patch_overlap_perc: 0





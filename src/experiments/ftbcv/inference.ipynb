{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "featured-marks",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T23:56:46.184885Z",
     "iopub.status.busy": "2021-09-15T23:56:46.184542Z",
     "iopub.status.idle": "2021-09-15T23:56:46.490194Z",
     "shell.execute_reply": "2021-09-15T23:56:46.489276Z",
     "shell.execute_reply.started": "2021-09-15T23:56:46.184856Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "## General Imports from all libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "import pathlib\n",
    "import glob\n",
    "import time\n",
    "import math, random\n",
    "import pprint\n",
    "import collections\n",
    "import numbers, string\n",
    "\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "from PIL import Image\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "curr_path = pathlib.Path(os.getcwd()).absolute()\n",
    "\n",
    "cards = !echo $SGE_HGR_gpu_card\n",
    "!export CUDA_VISIBLE_DEVICES=\"${SGE_HGR_gpu_card// /,}\"\n",
    "device = torch.device(f\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "# Import custom files for this project\n",
    "dest_path = str(curr_path.parent.parent)\n",
    "if dest_path not in sys.path:\n",
    "    print('Adding current path:', dest_path)\n",
    "    sys.path.append(str(dest_path))\n",
    "\n",
    "from run_experiment import batch_metrics, get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-humidity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T04:00:18.369643Z",
     "iopub.status.busy": "2021-09-10T04:00:18.369060Z",
     "iopub.status.idle": "2021-09-10T04:00:20.853714Z",
     "shell.execute_reply": "2021-09-10T04:00:20.852213Z",
     "shell.execute_reply.started": "2021-09-10T04:00:18.369586Z"
    },
    "tags": []
   },
   "source": [
    "# (0909) Inference with Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "durable-morris",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T23:54:13.662951Z",
     "iopub.status.busy": "2021-09-15T23:54:13.662293Z",
     "iopub.status.idle": "2021-09-15T23:54:13.739849Z",
     "shell.execute_reply": "2021-09-15T23:54:13.738820Z",
     "shell.execute_reply.started": "2021-09-15T23:54:13.662890Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Inference Constants\n",
    "infer_batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "focal-revolution",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-16T00:25:23.111535Z",
     "iopub.status.busy": "2021-09-16T00:25:23.110906Z",
     "iopub.status.idle": "2021-09-16T00:27:07.799720Z",
     "shell.execute_reply": "2021-09-16T00:27:07.798392Z",
     "shell.execute_reply.started": "2021-09-16T00:25:23.111477Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí† nnUNet3D model initiated with n_classes=14, \n",
      "   n_input=1, \n",
      "   params=16,478,616, trainable_params=16,478,616.\n",
      "   (Model) Successfully initialized weights via kaiming.\n",
      "<All keys matched successfully>\n",
      "Collecting data samples:\n",
      "    Took 36.01s for sample creation.\n",
      "    Took 39.08s for sample creation.\n",
      "    Took 39.18s for sample creation.\n",
      "    Took 40.91s for sample creation.\n",
      "    Took 41.24s for sample creation.\n",
      "    Took 41.87s for sample creation.\n",
      "    Took 41.94s for sample creation.\n",
      "    Took 42.05s for sample creation.\n",
      "    Took 43.38s for sample creation.\n",
      "    Took 43.42s for sample creation.\n",
      "    Took 43.70s for sample creation.\n",
      "    Took 43.89s for sample creation.\n",
      "    Took 44.08s for sample creation.\n",
      "    Took 44.48s for sample creation.\n",
      "    Took 45.32s for sample creation.\n",
      "    Took 46.50s for sample creation.\n",
      "    Took 48.79s for sample creation.\n",
      "    Took 50.18s for sample creation.\n",
      "    Took 53.15s for sample creation.\n",
      "    Took 55.64s for sample creation.\n",
      "    Took 58.30s for sample creation.\n",
      "    Took 59.03s for sample creation.\n",
      "    Took 63.29s for sample creation.\n",
      "    Took 28.81s for sample creation.\n",
      "    Took 72.06s for sample creation.\n",
      "    Took 34.27s for sample creation.\n",
      "    Took 35.12s for sample creation.\n",
      "    Took 46.59s for sample creation.\n",
      "    Took 42.93s for sample creation.\n",
      "    Took 56.51s for sample creation.\n",
      "[Took 102.71s to get samples!]\n",
      "\n",
      "Train Data Components:\n",
      "üí† ScaledForegroundCropper3d initiated (fg_p=0.5). \n",
      "   final_shape=[32, 176, 176], scale_range=[(1.0, 1.0), (0.8, 1.4), (0.8, 1.4)]\n",
      "   default_interpolation=trilinear, ret_record=True\n",
      "üí† BCVSampleSet created with 18 samples. \n",
      "   Train=True, Crops/Vol=100, Virtual-Size=1800, #Transforms=5.\n",
      "   Indices: [0, 4, 5, 8, 9, 11, 12, 13, 15, 16, 18, 19, 21, 22, 24, 26, 28, 29]\n",
      "üí† Torch Dataloader initialized with 2 workers!\n",
      "   Batch-size=2, Shuffle=True. \n",
      "\n",
      "\n",
      "Validation Data Components:\n",
      "üí† BCVSampleSet created with 6 samples. \n",
      "   Train=False, Crops/Vol=1, Virtual-Size=6, #Transforms=0.\n",
      "   Indices: [1, 7, 10, 14, 17, 23]\n",
      "\n",
      "Test Data Components:\n",
      "üí† BCVSampleSet created with 6 samples. \n",
      "   Train=False, Crops/Vol=1, Virtual-Size=6, #Transforms=0.\n",
      "   Indices: [2, 3, 6, 20, 25, 27]\n",
      "[Took 102.71 sec to load all data.]\n"
     ]
    }
   ],
   "source": [
    "## ------------- Get Config ------------\n",
    "from configs import get_config\n",
    "# cfg = get_config('./configs/ftbcv_train.yaml', merge_default=False)\n",
    "\n",
    "## ------------- Get Checkpoint -------------\n",
    "cp_file = './(0911bcv-3g)TUNE_nnunet3d_nesterov_cedc_s4_ftbcv_ep175_best-val-dice_mean-0.762.pth'\n",
    "cp_path = cp_file\n",
    "checkpoint = torch.load(cp_path, map_location='cpu')\n",
    "\n",
    "cfg = checkpoint['config']\n",
    "cfg.experiment.distributed = False\n",
    "cfg.experiment.rank = 0\n",
    "cfg.experiment.device = device\n",
    "cfg.experiment.gpu_idxs = cards[0].split(',')\n",
    "\n",
    "## -------------- Get Model --------------\n",
    "state_dict = checkpoint['state_dict']\n",
    "new_state_dict = collections.OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    new_state_dict['.'.join(k.split('.')[1:])] = v\n",
    "del state_dict\n",
    "\n",
    "model = get_model(cfg)['model']\n",
    "print(model.load_state_dict(new_state_dict))\n",
    "model = model.to(device)\n",
    "\n",
    "## ----------------- Get Data ----------------\n",
    "from experiments.ftbcv.data_setup import get_data_components\n",
    "data_d = get_data_components(cfg)\n",
    "val_set = data_d['val_set']\n",
    "test_set = data_d['test_set']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "voluntary-springfield",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-16T00:27:07.802197Z",
     "iopub.status.busy": "2021-09-16T00:27:07.801878Z",
     "iopub.status.idle": "2021-09-16T00:33:33.426296Z",
     "shell.execute_reply": "2021-09-16T00:33:33.424942Z",
     "shell.execute_reply.started": "2021-09-16T00:27:07.802165Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 2 -> 2\n",
      " üñºÔ∏è  Inference for example 1.\n",
      "     Getting predictions for 48 batches.\n",
      "Completed inference for vol 1 (26.32 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 2.\n",
      "     Getting predictions for 48 batches.\n",
      "Completed inference for vol 2 (27.18 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 3.\n",
      "     Getting predictions for 48 batches.\n",
      "Completed inference for vol 3 (27.35 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 4.\n",
      "     Getting predictions for 48 batches.\n",
      "Completed inference for vol 4 (27.45 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 5.\n",
      "     Getting predictions for 48 batches.\n",
      "Completed inference for vol 5 (26.76 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 6.\n",
      "     Getting predictions for 56 batches.\n",
      "Completed inference for vol 6 (31.55 sec).\n",
      "\n",
      "(Val) Sample 2, idx=1 \n",
      "       Dice: 0.83 \n",
      "        [0.954 0.887 0.919 0.783 0.765 0.96  0.909 0.88  0.876 0.79  0.747 0.715\n",
      " 0.639] \n",
      "       Jaccard: 0.72 \n",
      "        [0.913 0.797 0.851 0.643 0.619 0.923 0.832 0.785 0.78  0.653 0.596 0.556\n",
      " 0.47 ]\n",
      "(Val) Sample 8, idx=7 \n",
      "       Dice: 0.71 \n",
      "        [0.903 0.009 0.002 0.828 0.762 0.961 0.824 0.92  0.896 0.815 0.82  0.753\n",
      " 0.715] \n",
      "       Jaccard: 0.61 \n",
      "        [0.823 0.005 0.001 0.707 0.615 0.924 0.701 0.852 0.811 0.688 0.696 0.604\n",
      " 0.557]\n",
      "(Val) Sample 21, idx=10 \n",
      "       Dice: 0.76 \n",
      "        [0.918 0.897 0.929 0.87  0.76  0.966 0.738 0.925 0.723 0.607 0.626 0.557\n",
      " 0.374] \n",
      "       Jaccard: 0.64 \n",
      "        [0.849 0.813 0.868 0.769 0.613 0.935 0.585 0.86  0.567 0.436 0.455 0.386\n",
      " 0.23 ]\n",
      "(Val) Sample 25, idx=14 \n",
      "       Dice: 0.74 \n",
      "        [0.766 0.597 0.865 0.856 0.738 0.946 0.852 0.914 0.775 0.294 0.726 0.669\n",
      " 0.609] \n",
      "       Jaccard: 0.61 \n",
      "        [0.621 0.426 0.763 0.749 0.585 0.898 0.743 0.841 0.632 0.173 0.57  0.502\n",
      " 0.437]\n",
      "(Val) Sample 28, idx=17 \n",
      "       Dice: 0.73 \n",
      "        [0.927 0.896 0.89  0.132 0.842 0.882 0.829 0.93  0.888 0.606 0.733 0.214\n",
      " 0.684] \n",
      "       Jaccard: 0.62 \n",
      "        [0.864 0.812 0.802 0.071 0.727 0.788 0.708 0.869 0.798 0.435 0.579 0.12\n",
      " 0.52 ]\n",
      "(Val) Sample 34, idx=23 \n",
      "       Dice: 0.80 \n",
      "        [0.939 0.769 0.851 0.619 0.742 0.945 0.914 0.922 0.885 0.711 0.806 0.65\n",
      " 0.692] \n",
      "       Jaccard: 0.69 \n",
      "        [0.886 0.624 0.741 0.448 0.59  0.896 0.842 0.856 0.793 0.552 0.675 0.481\n",
      " 0.529]\n",
      "StopWatch(Val) took 3.17 min\n",
      "{'dice_mean': 0.761918671499552, 'jaccard_mean': 0.6501557788732583}\n",
      " üñºÔ∏è  Inference for example 1.\n",
      "     Getting predictions for 64 batches.\n",
      "Completed inference for vol 1 (35.43 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 2.\n",
      "     Getting predictions for 48 batches.\n",
      "Completed inference for vol 2 (27.44 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 3.\n",
      "     Getting predictions for 56 batches.\n",
      "Completed inference for vol 3 (31.72 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 4.\n",
      "     Getting predictions for 32 batches.\n",
      "Completed inference for vol 4 (18.46 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 5.\n",
      "     Getting predictions for 56 batches.\n",
      "Completed inference for vol 5 (31.42 sec).\n",
      "\n",
      " üñºÔ∏è  Inference for example 6.\n",
      "     Getting predictions for 56 batches.\n",
      "Completed inference for vol 6 (31.89 sec).\n",
      "\n",
      "(Test) Sample 3, idx=2 \n",
      "       Dice: 0.70 \n",
      "        [0.55  0.66  0.773 0.863 0.357 0.927 0.609 0.839 0.743 0.689 0.844 0.673\n",
      " 0.629] \n",
      "       Jaccard: 0.56 \n",
      "        [0.379 0.493 0.63  0.759 0.218 0.864 0.438 0.722 0.591 0.525 0.729 0.507\n",
      " 0.458]\n",
      "(Test) Sample 4, idx=3 \n",
      "       Dice: 0.79 \n",
      "        [0.931 0.82  0.694 0.679 0.847 0.956 0.681 0.928 0.904 0.734 0.716 0.713\n",
      " 0.623] \n",
      "       Jaccard: 0.66 \n",
      "        [0.872 0.695 0.531 0.514 0.735 0.915 0.516 0.865 0.825 0.58  0.558 0.554\n",
      " 0.452]\n",
      "(Test) Sample 7, idx=6 \n",
      "       Dice: 0.61 \n",
      "        [0.725 0.76  0.846 0.    0.422 0.836 0.635 0.707 0.794 0.716 0.635 0.182\n",
      " 0.615] \n",
      "       Jaccard: 0.47 \n",
      "        [0.569 0.613 0.733 0.    0.268 0.719 0.465 0.547 0.658 0.557 0.466 0.1\n",
      " 0.444]\n",
      "(Test) Sample 31, idx=20 \n",
      "       Dice: 0.85 \n",
      "        [0.955 0.946 0.947 0.87  0.832 0.961 0.854 0.922 0.834 0.802 0.806 0.606\n",
      " 0.697] \n",
      "       Jaccard: 0.75 \n",
      "        [0.913 0.898 0.9   0.77  0.712 0.925 0.745 0.855 0.715 0.669 0.676 0.435\n",
      " 0.534]\n",
      "(Test) Sample 36, idx=25 \n",
      "       Dice: 0.82 \n",
      "        [0.951 0.955 0.936 0.644 0.755 0.963 0.89  0.908 0.862 0.725 0.718 0.684\n",
      " 0.637] \n",
      "       Jaccard: 0.71 \n",
      "        [0.907 0.914 0.88  0.475 0.606 0.929 0.802 0.831 0.758 0.569 0.56  0.519\n",
      " 0.468]\n",
      "(Test) Sample 38, idx=27 \n",
      "       Dice: 0.78 \n",
      "        [0.903 0.923 0.923 0.561 0.715 0.952 0.637 0.908 0.824 0.734 0.825 0.694\n",
      " 0.492] \n",
      "       Jaccard: 0.66 \n",
      "        [0.823 0.858 0.857 0.39  0.556 0.908 0.468 0.831 0.701 0.579 0.702 0.531\n",
      " 0.327]\n",
      "StopWatch(Test) took 3.25 min\n",
      "{'dice_mean': 0.7564855621615746, 'jaccard_mean': 0.6353847981313652}\n"
     ]
    }
   ],
   "source": [
    "## Run Val Inference\n",
    "print('batch_size:', cfg.test.batch_size, '->', infer_batch_size)\n",
    "cfg.test.batch_size = infer_batch_size\n",
    "metrics_queue = torch.multiprocessing.Queue()\n",
    "\n",
    "from run_experiment import test_metrics\n",
    "print(test_metrics(cfg, model, val_set, 0, metrics_queue, len(val_set),\n",
    "                   name='val', overlap_perc=0.2))\n",
    "print(test_metrics(cfg, model, test_set, 0, metrics_queue, len(test_set),\n",
    "                   name='test', overlap_perc=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-medicaid",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T04:06:03.621831Z",
     "iopub.status.busy": "2021-09-10T04:06:03.621257Z",
     "iopub.status.idle": "2021-09-10T04:06:04.264520Z",
     "shell.execute_reply": "2021-09-10T04:06:04.263154Z",
     "shell.execute_reply.started": "2021-09-10T04:06:03.621776Z"
    },
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# (0901) Pengfei Inference Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-honduras",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T05:34:03.174227Z",
     "iopub.status.busy": "2021-09-01T05:34:03.173579Z",
     "iopub.status.idle": "2021-09-01T05:34:03.240663Z",
     "shell.execute_reply": "2021-09-01T05:34:03.239433Z",
     "shell.execute_reply.started": "2021-09-01T05:34:03.174147Z"
    },
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Data Collection and Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "destroyed-oliver",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:38:35.095024Z",
     "iopub.status.busy": "2021-09-02T17:38:35.094743Z",
     "iopub.status.idle": "2021-09-02T17:38:35.146658Z",
     "shell.execute_reply": "2021-09-02T17:38:35.145565Z",
     "shell.execute_reply.started": "2021-09-02T17:38:35.094993Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_imgs_masks_info(args):\n",
    "    images_f, mask_f = args\n",
    "    # 1. Read image and preprocess (clamp + normalize)\n",
    "    sitk_image = sitk.ReadImage(image_f, sitk.sitkInt16)\n",
    "    sitk_image = sitk.Clamp(sitk_image, sitk.sitkInt16, -1024, 325)\n",
    "    sitk_image = sitk.NormalizeImageFilter().Execute(sitk_image)\n",
    "    image_tensor = torch.from_numpy(sitk.GetArrayFromImage(sitk_image))\n",
    "    image_tensor = image_tensor.float()\n",
    "\n",
    "    # 2. Read mask and convert it to one-hot\n",
    "    sitk_mask = sitk.ReadImage(mask_f, sitk.sitkInt64)\n",
    "    mask_tensor = torch.from_numpy(sitk.GetArrayFromImage(sitk_mask))\n",
    "\n",
    "    shape = image_tensor.shape\n",
    "    oh_shape = [num_classes] + list(shape)\n",
    "    mask_oh_tensor = torch.zeros(oh_shape, dtype=torch.int32)\n",
    "    mask_oh_tensor.scatter_(0, mask_tensor.unsqueeze(0), 1)\n",
    "    \n",
    "    info = {\n",
    "        'origin': sitk_image.GetOrigin(),\n",
    "        'spacing': sitk_image.GetSpacing(),\n",
    "        'direction': sitk_image.GetDirection()\n",
    "    }\n",
    "    return image_tensor, mask_oh_tensor, info\n",
    "    \n",
    "    \n",
    "class MockDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, mask_files, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.image_files = image_files  # list of image files\n",
    "        self.mask_files = mask_files  # list of mask files\n",
    "        \n",
    "        # Get image tensors and store permanently\n",
    "        self.images, self.masks, self.image_info = [], [], []\n",
    "        args = []\n",
    "        for image_f, mask_f in zip(image_files, mask_files):\n",
    "            args.append((image_f, mask_f))\n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "        info_d = self.image_info[idx]\n",
    "        return image, mask, info_d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "disciplinary-signal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:38:35.148093Z",
     "iopub.status.busy": "2021-09-02T17:38:35.147671Z",
     "iopub.status.idle": "2021-09-02T17:38:54.653582Z",
     "shell.execute_reply": "2021-09-02T17:38:54.652372Z",
     "shell.execute_reply.started": "2021-09-02T17:38:35.148042Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 19.28532838821411 sec to load 6 test images.\n"
     ]
    }
   ],
   "source": [
    "bcv_dir = pathlib.Path('/afs/crc.nd.edu/user/y/yzhang46/datasets/BCV-2015')\n",
    "train_image_dir = bcv_dir / 'train' / 'img_nii'\n",
    "train_mask_dir = bcv_dir / 'train' / 'label_nii'\n",
    "\n",
    "images = sorted(glob.glob(str(train_image_dir) + '/*.nii.gz'))\n",
    "masks = sorted(glob.glob(str(train_mask_dir) + '/*.nii.gz'))\n",
    "\n",
    "start = time.time()\n",
    "test_size = 6\n",
    "num_classes = 14\n",
    "test_set = MockDataset(images[:test_size], masks[:test_size], num_classes)\n",
    "print(f'Took {time.time() - start} sec to load {test_size} test images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-treaty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T05:34:44.322598Z",
     "iopub.status.busy": "2021-09-01T05:34:44.321994Z",
     "iopub.status.idle": "2021-09-01T05:34:44.386440Z",
     "shell.execute_reply": "2021-09-01T05:34:44.385229Z",
     "shell.execute_reply.started": "2021-09-01T05:34:44.322544Z"
    },
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spoken-elizabeth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:38:54.655645Z",
     "iopub.status.busy": "2021-09-02T17:38:54.655361Z",
     "iopub.status.idle": "2021-09-02T17:38:54.998082Z",
     "shell.execute_reply": "2021-09-02T17:38:54.997212Z",
     "shell.execute_reply.started": "2021-09-02T17:38:54.655614Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí† UNet3D-PGL model initiated with n_classes=14, \n",
      "   n_input=1, activation=relu, \n",
      "   params=19,074,510, trainable_params=19,074,510.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = '(0831)bcv-scratch_adam_dice_s3_finetune_bcv_ep499_last.pth'\n",
    "checkpoint = torch.load(file, map_location='cpu')\n",
    "\n",
    "from lib.nets.volumetric.resunet3d import UNet3D\n",
    "# model = UNet3D(1, 14, final_sigmoid=False, is_segmentation=False)\n",
    "\n",
    "from experiments.finetune_bcv.ftbcv_unet3d import UNet3D as genesis_unet3d\n",
    "model = genesis_unet3d(n_input=1, n_class=14, act='relu')\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-dictionary",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "western-draft",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:39:31.145551Z",
     "iopub.status.busy": "2021-09-02T17:39:31.144913Z",
     "iopub.status.idle": "2021-09-02T17:40:53.492826Z",
     "shell.execute_reply": "2021-09-02T17:40:53.491616Z",
     "shell.execute_reply.started": "2021-09-02T17:39:31.145495Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚≠ê Inference for example 1..\n",
      "Batch 1 / 16\n",
      "Batch 2 / 16\n",
      "Batch 3 / 16\n",
      "Batch 4 / 16\n",
      "Batch 5 / 16\n",
      "Batch 6 / 16\n",
      "Batch 7 / 16\n",
      "Batch 8 / 16\n",
      "Batch 9 / 16\n",
      "Batch 10 / 16\n",
      "Batch 11 / 16\n",
      "Batch 12 / 16\n",
      "Batch 13 / 16\n",
      "Batch 14 / 16\n",
      "Batch 15 / 16\n",
      "Batch 16 / 16\n",
      "Aggregate (divide):  3.136298656463623\n",
      "Aggregate:  14.577434301376343\n",
      "Getting image metrics..\n",
      "0.06910467892885208 [0.967 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.   ]\n",
      "0.0669272169470787 [0.937 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.   ]\n",
      "Mets time: 18.30\n",
      "Saving image..\n",
      "Completed inference for test volume 1 (82.26).\n"
     ]
    }
   ],
   "source": [
    "from data.transforms.crops.inference import ChopBatchAggregate3d as CBA\n",
    "\n",
    "num_classes = 14\n",
    "device = 'cuda'\n",
    "dataset = test_set\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(len(dataset)):\n",
    "        start_vol = time.time()\n",
    "        print(f'‚≠ê Inference for example {i+1}..')\n",
    "        image, mask, info = dataset[i]  # image: DxHxW, mask: CxDxHxW\n",
    "                                        #  image: float32, mask: int32\n",
    "        \n",
    "        # Create Chop, batch, aggregator object\n",
    "        image = image   # faster calc with GPUs\n",
    "        mask = mask\n",
    "        cba = CBA(image, (48, 160, 160), (0, 0, 0), 4, num_classes)\n",
    "        \n",
    "        # Run inference on batches of crops of image\n",
    "        for bidx, batch in enumerate(cba):\n",
    "            print(f'Batch {bidx + 1} / {len(cba)}')\n",
    "            crops, locations = batch\n",
    "            crops = crops.to(device)\n",
    "            \n",
    "            logits = model(crops)['out']\n",
    "    \n",
    "            cba.add_batch_predictions(logits.cpu(), locations, act='none')\n",
    "                # NOTE: in this case, we are averaging logits, if you want\n",
    "                #  to average probabilities instead, use act='softmax'\n",
    "        \n",
    "        # Get final predictions, calculate metrics\n",
    "        agg_predictions = cba.aggregate(ret='one_hot', cpu=True, numpy=False)\n",
    "        \n",
    "        print(f'Getting image metrics..')\n",
    "        start = time.time()\n",
    "        mets = batch_metrics(agg_predictions.unsqueeze(0), mask.unsqueeze(0))\n",
    "            # preds are CxDxHxW, but batch input takes 1xCxDxHxW\n",
    "        print(mets['dice_mean'], mets['dice_class'])\n",
    "        print(mets['jaccard_mean'], mets['jaccard_class'])\n",
    "        print(f'Mets time: {time.time() - start:.2f}')\n",
    "        \n",
    "        # Convert from 1hot to id and save prediction volume\n",
    "        print(f'Saving image..')\n",
    "        id_preds = agg_predictions.argmax(0).numpy().astype(np.uint16)\n",
    "        sitk_pred = sitk.GetImageFromArray(id_preds, isVector=False)\n",
    "        sitk_pred.SetOrigin(info['origin'])\n",
    "        sitk_pred.SetSpacing(info['spacing'])\n",
    "        sitk_pred.SetDirection(info['direction'])\n",
    "        sitk.WriteImage(sitk_pred, 'prediction.nii.gz')\n",
    "        \n",
    "        elapsed = time.time() - start_vol\n",
    "        print(f'Completed inference for test volume {i+1} ({elapsed:.2f}).')\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "excessive-championship",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:46:07.299252Z",
     "iopub.status.busy": "2021-09-02T17:46:07.298580Z",
     "iopub.status.idle": "2021-09-02T17:46:07.426552Z",
     "shell.execute_reply": "2021-09-02T17:46:07.425289Z",
     "shell.execute_reply.started": "2021-09-02T17:46:07.299195Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.argmax(1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-worse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

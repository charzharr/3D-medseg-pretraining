{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "standard-victorian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:38:32.574810Z",
     "iopub.status.busy": "2021-09-02T17:38:32.574236Z",
     "iopub.status.idle": "2021-09-02T17:38:34.008130Z",
     "shell.execute_reply": "2021-09-02T17:38:34.007097Z",
     "shell.execute_reply.started": "2021-09-02T17:38:32.574682Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "## General Imports from all libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "import pathlib\n",
    "import glob\n",
    "import time\n",
    "import math, random\n",
    "import pprint\n",
    "import collections\n",
    "import numbers, string\n",
    "\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "from PIL import Image\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "curr_path = pathlib.Path(os.getcwd()).absolute()\n",
    "\n",
    "cards = !echo $SGE_HGR_gpu_card\n",
    "device = torch.device(f\"cuda:{cards[0]}\" if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assisted-cleaning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:38:34.009827Z",
     "iopub.status.busy": "2021-09-02T17:38:34.009565Z",
     "iopub.status.idle": "2021-09-02T17:38:35.093080Z",
     "shell.execute_reply": "2021-09-02T17:38:35.091837Z",
     "shell.execute_reply.started": "2021-09-02T17:38:34.009798Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding current path: /afs/crc.nd.edu/user/y/yzhang46/_3DPRE/src\n"
     ]
    }
   ],
   "source": [
    "# Import custom files for this project\n",
    "dest_path = str(curr_path.parent.parent)\n",
    "if dest_path not in sys.path:\n",
    "    print('Adding current path:', dest_path)\n",
    "    sys.path.append(str(dest_path))\n",
    "\n",
    "from run_experiment import batch_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-richmond",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T05:34:03.174227Z",
     "iopub.status.busy": "2021-09-01T05:34:03.173579Z",
     "iopub.status.idle": "2021-09-01T05:34:03.240663Z",
     "shell.execute_reply": "2021-09-01T05:34:03.239433Z",
     "shell.execute_reply.started": "2021-09-01T05:34:03.174147Z"
    },
    "tags": []
   },
   "source": [
    "# Data Collection and Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "excessive-affiliate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:38:35.095024Z",
     "iopub.status.busy": "2021-09-02T17:38:35.094743Z",
     "iopub.status.idle": "2021-09-02T17:38:35.146658Z",
     "shell.execute_reply": "2021-09-02T17:38:35.145565Z",
     "shell.execute_reply.started": "2021-09-02T17:38:35.094993Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_imgs_masks_info(args):\n",
    "    images_f, mask_f = args\n",
    "    # 1. Read image and preprocess (clamp + normalize)\n",
    "    sitk_image = sitk.ReadImage(image_f, sitk.sitkInt16)\n",
    "    sitk_image = sitk.Clamp(sitk_image, sitk.sitkInt16, -1024, 325)\n",
    "    sitk_image = sitk.NormalizeImageFilter().Execute(sitk_image)\n",
    "    image_tensor = torch.from_numpy(sitk.GetArrayFromImage(sitk_image))\n",
    "    image_tensor = image_tensor.float()\n",
    "\n",
    "    # 2. Read mask and convert it to one-hot\n",
    "    sitk_mask = sitk.ReadImage(mask_f, sitk.sitkInt64)\n",
    "    mask_tensor = torch.from_numpy(sitk.GetArrayFromImage(sitk_mask))\n",
    "\n",
    "    shape = image_tensor.shape\n",
    "    oh_shape = [num_classes] + list(shape)\n",
    "    mask_oh_tensor = torch.zeros(oh_shape, dtype=torch.int32)\n",
    "    mask_oh_tensor.scatter_(0, mask_tensor.unsqueeze(0), 1)\n",
    "    \n",
    "    info = {\n",
    "        'origin': sitk_image.GetOrigin(),\n",
    "        'spacing': sitk_image.GetSpacing(),\n",
    "        'direction': sitk_image.GetDirection()\n",
    "    }\n",
    "    return image_tensor, mask_oh_tensor, info\n",
    "    \n",
    "    \n",
    "class MockDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, mask_files, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.image_files = image_files  # list of image files\n",
    "        self.mask_files = mask_files  # list of mask files\n",
    "        \n",
    "        # Get image tensors and store permanently\n",
    "        self.images, self.masks, self.image_info = [], [], []\n",
    "        args = []\n",
    "        for image_f, mask_f in zip(image_files, mask_files):\n",
    "            args.append((image_f, mask_f))\n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "        info_d = self.image_info[idx]\n",
    "        return image, mask, info_d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "thrown-consumption",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:38:35.148093Z",
     "iopub.status.busy": "2021-09-02T17:38:35.147671Z",
     "iopub.status.idle": "2021-09-02T17:38:54.653582Z",
     "shell.execute_reply": "2021-09-02T17:38:54.652372Z",
     "shell.execute_reply.started": "2021-09-02T17:38:35.148042Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 19.28532838821411 sec to load 6 test images.\n"
     ]
    }
   ],
   "source": [
    "bcv_dir = pathlib.Path('/afs/crc.nd.edu/user/y/yzhang46/datasets/BCV-2015')\n",
    "train_image_dir = bcv_dir / 'train' / 'img_nii'\n",
    "train_mask_dir = bcv_dir / 'train' / 'label_nii'\n",
    "\n",
    "images = sorted(glob.glob(str(train_image_dir) + '/*.nii.gz'))\n",
    "masks = sorted(glob.glob(str(train_mask_dir) + '/*.nii.gz'))\n",
    "\n",
    "start = time.time()\n",
    "test_size = 6\n",
    "num_classes = 14\n",
    "test_set = MockDataset(images[:test_size], masks[:test_size], num_classes)\n",
    "print(f'Took {time.time() - start} sec to load {test_size} test images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-iraqi",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T05:34:44.322598Z",
     "iopub.status.busy": "2021-09-01T05:34:44.321994Z",
     "iopub.status.idle": "2021-09-01T05:34:44.386440Z",
     "shell.execute_reply": "2021-09-01T05:34:44.385229Z",
     "shell.execute_reply.started": "2021-09-01T05:34:44.322544Z"
    },
    "tags": []
   },
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afraid-native",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:38:54.655645Z",
     "iopub.status.busy": "2021-09-02T17:38:54.655361Z",
     "iopub.status.idle": "2021-09-02T17:38:54.998082Z",
     "shell.execute_reply": "2021-09-02T17:38:54.997212Z",
     "shell.execute_reply.started": "2021-09-02T17:38:54.655614Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí† UNet3D-PGL model initiated with n_classes=14, \n",
      "   n_input=1, activation=relu, \n",
      "   params=19,074,510, trainable_params=19,074,510.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = '(0831)bcv-scratch_adam_dice_s3_finetune_bcv_ep499_last.pth'\n",
    "checkpoint = torch.load(file, map_location='cpu')\n",
    "\n",
    "from lib.nets.volumetric.resunet3d import UNet3D\n",
    "# model = UNet3D(1, 14, final_sigmoid=False, is_segmentation=False)\n",
    "\n",
    "from experiments.finetune_bcv.ftbcv_unet3d import UNet3D as genesis_unet3d\n",
    "model = genesis_unet3d(n_input=1, n_class=14, act='relu')\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-dependence",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "meaningful-palestine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:39:31.145551Z",
     "iopub.status.busy": "2021-09-02T17:39:31.144913Z",
     "iopub.status.idle": "2021-09-02T17:40:53.492826Z",
     "shell.execute_reply": "2021-09-02T17:40:53.491616Z",
     "shell.execute_reply.started": "2021-09-02T17:39:31.145495Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚≠ê Inference for example 1..\n",
      "Batch 1 / 16\n",
      "Batch 2 / 16\n",
      "Batch 3 / 16\n",
      "Batch 4 / 16\n",
      "Batch 5 / 16\n",
      "Batch 6 / 16\n",
      "Batch 7 / 16\n",
      "Batch 8 / 16\n",
      "Batch 9 / 16\n",
      "Batch 10 / 16\n",
      "Batch 11 / 16\n",
      "Batch 12 / 16\n",
      "Batch 13 / 16\n",
      "Batch 14 / 16\n",
      "Batch 15 / 16\n",
      "Batch 16 / 16\n",
      "Aggregate (divide):  3.136298656463623\n",
      "Aggregate:  14.577434301376343\n",
      "Getting image metrics..\n",
      "0.06910467892885208 [0.967 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.   ]\n",
      "0.0669272169470787 [0.937 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.   ]\n",
      "Mets time: 18.30\n",
      "Saving image..\n",
      "Completed inference for test volume 1 (82.26).\n"
     ]
    }
   ],
   "source": [
    "from data.transforms.crops.inference import ChopBatchAggregate3d as CBA\n",
    "\n",
    "num_classes = 14\n",
    "device = 'cuda'\n",
    "dataset = test_set\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(len(dataset)):\n",
    "        start_vol = time.time()\n",
    "        print(f'‚≠ê Inference for example {i+1}..')\n",
    "        image, mask, info = dataset[i]  # image: DxHxW, mask: CxDxHxW\n",
    "                                        #  image: float32, mask: int32\n",
    "        \n",
    "        # Create Chop, batch, aggregator object\n",
    "        image = image   # faster calc with GPUs\n",
    "        mask = mask\n",
    "        cba = CBA(image, (48, 160, 160), (0, 0, 0), 4, num_classes)\n",
    "        \n",
    "        # Run inference on batches of crops of image\n",
    "        for bidx, batch in enumerate(cba):\n",
    "            print(f'Batch {bidx + 1} / {len(cba)}')\n",
    "            crops, locations = batch\n",
    "            crops = crops.to(device)\n",
    "            \n",
    "            logits = model(crops)['out']\n",
    "    \n",
    "            cba.add_batch_predictions(logits.cpu(), locations, act='none')\n",
    "                # NOTE: in this case, we are averaging logits, if you want\n",
    "                #  to average probabilities instead, use act='softmax'\n",
    "        \n",
    "        # Get final predictions, calculate metrics\n",
    "        agg_predictions = cba.aggregate(ret='one_hot', cpu=True, numpy=False)\n",
    "        \n",
    "        print(f'Getting image metrics..')\n",
    "        start = time.time()\n",
    "        mets = batch_metrics(agg_predictions.unsqueeze(0), mask.unsqueeze(0))\n",
    "            # preds are CxDxHxW, but batch input takes 1xCxDxHxW\n",
    "        print(mets['dice_mean'], mets['dice_class'])\n",
    "        print(mets['jaccard_mean'], mets['jaccard_class'])\n",
    "        print(f'Mets time: {time.time() - start:.2f}')\n",
    "        \n",
    "        # Convert from 1hot to id and save prediction volume\n",
    "        print(f'Saving image..')\n",
    "        id_preds = agg_predictions.argmax(0).numpy().astype(np.uint16)\n",
    "        sitk_pred = sitk.GetImageFromArray(id_preds, isVector=False)\n",
    "        sitk_pred.SetOrigin(info['origin'])\n",
    "        sitk_pred.SetSpacing(info['spacing'])\n",
    "        sitk_pred.SetDirection(info['direction'])\n",
    "        sitk.WriteImage(sitk_pred, 'prediction.nii.gz')\n",
    "        \n",
    "        elapsed = time.time() - start_vol\n",
    "        print(f'Completed inference for test volume {i+1} ({elapsed:.2f}).')\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "valid-princess",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T17:46:07.299252Z",
     "iopub.status.busy": "2021-09-02T17:46:07.298580Z",
     "iopub.status.idle": "2021-09-02T17:46:07.426552Z",
     "shell.execute_reply": "2021-09-02T17:46:07.425289Z",
     "shell.execute_reply.started": "2021-09-02T17:46:07.299195Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.argmax(1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-curve",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
